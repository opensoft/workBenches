# THE BIG HEAVY PYTHON DEVELOPMENT MONSTER - Ubuntu 24.04 Edition
# Build arguments for customization:
# - INSTALL_CLOUD_TOOLS: Install AWS CLI, Azure CLI, Google Cloud SDK, kubectl, helm, terraform (default: true)
# - INSTALL_ML_FRAMEWORKS: Install ML/AI frameworks like TensorFlow, PyTorch, transformers (default: true)
# - INSTALL_ADDITIONAL_EDITORS: Install emacs-nox (default: false)
# - INSTALL_NETWORK_TOOLS: Install network analysis tools like nmap, wireshark (default: true)
# - INSTALL_SECURITY_TOOLS: Install security scanning tools like trivy (default: true)
# - PYTHON_VERSION: Default Python version to use (default: 3.12)
FROM ubuntu:24.04

# Avoid interactive prompts
ENV DEBIAN_FRONTEND=noninteractive
ENV TZ=UTC

USER root

# Accept build arguments for username, UID, and GID from docker-compose
ARG USERNAME
ARG USER_UID
ARG USER_GID
ARG DEBUG=false

# Build arguments for optional components (modularity)
ARG INSTALL_CLOUD_TOOLS=true
ARG INSTALL_ML_FRAMEWORKS=true
ARG INSTALL_ADDITIONAL_EDITORS=false
ARG INSTALL_NETWORK_TOOLS=true
ARG INSTALL_SECURITY_TOOLS=true
ARG PYTHON_VERSION=3.12

# Set DEBUG as an environment variable for runtime
ENV DEBUG=${DEBUG}

# Python-specific environment variables
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
ENV PYTHONIOENCODING=utf-8
ENV LANG=C.UTF-8
ENV LC_ALL=C.UTF-8
ENV PYTHON_VERSION=${PYTHON_VERSION}

# Additional environment variables for development
ENV EDITOR=vim
ENV SHELL=/bin/zsh

# In debug mode, show these values
RUN if [ "$DEBUG" = "true" ]; then \
        echo "🐍 THE BIG HEAVY PYTHON DEVELOPMENT MONSTER"; \
        echo "the passed arg USERNAME= ${USERNAME}"; \
        echo "the passed arg USER_UID= ${USER_UID}"; \
        echo "the passed arg USER_GID= ${USER_GID}"; \
        echo "the passed env DEBUG= ${DEBUG}"; \
    fi

# Always log the resolved values for debugging
RUN echo "Resolved USERNAME=${USERNAME}, USER_UID=${USER_UID}, USER_GID=${USER_GID}, DEBUG=${DEBUG}"

# ========================================
# PHASE 1: SYSTEM FOUNDATION & REPOSITORIES
# ========================================

# Update and install essential system packages
RUN apt-get update && apt-get install -y \
    apt-transport-https \
    ca-certificates \
    gnupg \
    lsb-release \
    software-properties-common \
    curl \
    wget \
    gpg \
    && rm -rf /var/lib/apt/lists/*

# Add deadsnakes PPA for multiple Python versions
RUN add-apt-repository ppa:deadsnakes/ppa

# Add Node.js 20.x repository (for Jupyter extensions and web dev)
RUN curl -fsSL https://deb.nodesource.com/setup_20.x | bash -

# Add Docker repository
RUN curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg \
    && echo "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | tee /etc/apt/sources.list.d/docker.list > /dev/null

# Add Kubernetes repository
RUN curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.28/deb/Release.key | gpg --dearmor -o /usr/share/keyrings/kubernetes-apt-keyring.gpg \
    && echo 'deb [signed-by=/usr/share/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.28/deb/ /' | tee /etc/apt/sources.list.d/kubernetes.list

# Add PostgreSQL repository for latest version
RUN curl -fsSL https://www.postgresql.org/media/keys/ACCC4CF8.asc | gpg --dearmor -o /usr/share/keyrings/postgresql-keyring.gpg \
    && echo "deb [signed-by=/usr/share/keyrings/postgresql-keyring.gpg] http://apt.postgresql.org/pub/repos/apt/ $(lsb_release -cs)-pgdg main" | tee /etc/apt/sources.list.d/postgresql.list

# ========================================
# PHASE 2: THE PYTHON MONSTER PACKAGE INSTALLATION
# ========================================

# Phase 2a: Core development tools
RUN apt-get update && apt-get install -y \
    build-essential \
    cmake \
    ninja-build \
    pkg-config \
    autoconf \
    automake \
    libtool \
    make \
    gcc \
    g++ \
    gdb \
    valgrind \
    clang \
    llvm \
    && rm -rf /var/lib/apt/lists/*

# Phase 2b: Python ecosystem - Multiple Python versions
# Note: distutils was deprecated in Python 3.10 and removed in 3.12
# We use setuptools as the modern replacement for packaging
RUN apt-get update && apt-get install -y \
    python${PYTHON_VERSION} \
    python${PYTHON_VERSION}-dev \
    python${PYTHON_VERSION}-venv \
    python3.11 \
    python3.11-dev \
    python3.11-venv \
    python3.10 \
    python3.10-dev \
    python3.10-venv \
    python3-pip \
    python-is-python3 \
    && rm -rf /var/lib/apt/lists/*

# Phase 2c: Python development libraries and headers
RUN apt-get update && apt-get install -y \
    libpython3.12-dev \
    libpython3.11-dev \
    libpython3.10-dev \
    python3-setuptools \
    python3-wheel \
    python3-tk \
    python3-build \
    && rm -rf /var/lib/apt/lists/*

# Phase 2d: Scientific computing and data science dependencies
RUN apt-get update && apt-get install -y \
    libblas-dev \
    liblapack-dev \
    gfortran \
    libatlas-base-dev \
    libopenblas-dev \
    libhdf5-dev \
    libnetcdf-dev \
    libfftw3-dev \
    && rm -rf /var/lib/apt/lists/*

# Phase 2e: Graphics and image processing libraries
RUN apt-get update && apt-get install -y \
    libfreetype6-dev \
    libpng-dev \
    libjpeg-dev \
    libtiff5-dev \
    libwebp-dev \
    libopencv-dev \
    libcairo2-dev \
    libgirepository1.0-dev \
    && rm -rf /var/lib/apt/lists/*

# Phase 2f: Database libraries and clients
RUN apt-get update && apt-get install -y \
    libpq-dev \
    postgresql-client \
    mysql-client \
    sqlite3 \
    libsqlite3-dev \
    redis-tools \
    libmysqlclient-dev \
    && rm -rf /var/lib/apt/lists/*

# Phase 2g: Node.js (for Jupyter extensions and web development)
RUN apt-get update && apt-get install -y \
    nodejs \
    && rm -rf /var/lib/apt/lists/*

# Phase 2h: Additional language support
RUN apt-get update && apt-get install -y \
    golang-go \
    openjdk-21-jdk \
    && rm -rf /var/lib/apt/lists/*

# Phase 2i: Shell and terminal tools
RUN apt-get update && apt-get install -y \
    zsh \
    fish \
    tmux \
    screen \
    htop \
    neofetch \
    tree \
    && rm -rf /var/lib/apt/lists/*

# Phase 2j: Text editors and processing tools
RUN apt-get update && apt-get install -y \
    vim \
    neovim \
    nano \
    jq \
    xmlstarlet \
    ripgrep \
    fd-find \
    fzf \
    bat \
    && if [ "$INSTALL_ADDITIONAL_EDITORS" = "true" ]; then \
        apt-get install -y emacs-nox; \
    fi \
    && rm -rf /var/lib/apt/lists/*

# Phase 2k: Network tools (conditional)
RUN if [ "$INSTALL_NETWORK_TOOLS" = "true" ]; then \
    apt-get update && apt-get install -y \
        net-tools \
        nmap \
        netcat-openbsd \
        telnet \
        dnsutils \
        traceroute \
        httpie \
        && rm -rf /var/lib/apt/lists/*; \
    fi

# Phase 2l: Archive tools
RUN apt-get update && apt-get install -y \
    unzip \
    zip \
    p7zip-full \
    tar \
    gzip \
    bzip2 \
    xz-utils \
    && rm -rf /var/lib/apt/lists/*

# Phase 2m: Version control
RUN apt-get update && apt-get install -y \
    git \
    git-lfs \
    subversion \
    mercurial \
    && rm -rf /var/lib/apt/lists/*

# Phase 2n: Docker and container tools
RUN apt-get update && apt-get install -y \
    docker-ce \
    docker-ce-cli \
    containerd.io \
    docker-compose-plugin \
    && rm -rf /var/lib/apt/lists/*

# Phase 2o: Cloud tools (conditional)
RUN if [ "$INSTALL_CLOUD_TOOLS" = "true" ]; then \
    apt-get update && apt-get install -y \
        kubectl \
        && rm -rf /var/lib/apt/lists/*; \
    fi

# Phase 2p: System utilities
RUN apt-get update && apt-get install -y \
    sudo \
    less \
    rsync \
    lsof \
    strace \
    ltrace \
    file \
    plocate \
    && rm -rf /var/lib/apt/lists/*

# Phase 2q: Modern alternatives (optional installations)
RUN apt-get update && apt-get install -y \
    btop \
    && rm -rf /var/lib/apt/lists/*

# ========================================
# PHASE 3: PYTHON PACKAGE MANAGERS & TOOLS
# ========================================

# Ensure pip is up-to-date for the default Python version
# setuptools replaces distutils for all Python versions
RUN python${PYTHON_VERSION} -m pip install --upgrade --no-cache-dir pip setuptools wheel

# Ensure setuptools is available for all Python versions
RUN python3.11 -m pip install --upgrade --no-cache-dir pip setuptools wheel
RUN python3.10 -m pip install --upgrade --no-cache-dir pip setuptools wheel

# Install modern Python package managers
RUN python${PYTHON_VERSION} -m pip install --no-cache-dir pipx uv

# Install pyenv for managing Python versions
RUN curl https://pyenv.run | bash

# Install poetry (modern dependency management)
RUN curl -sSL https://install.python-poetry.org | python${PYTHON_VERSION} -

# Install pipenv
RUN python${PYTHON_VERSION} -m pip install pipenv

# ========================================
# PHASE 4: CORE PYTHON LIBRARIES (SPLIT INTO CHUNKS)
# ========================================

# Phase 4a: Core data science stack
RUN uv pip install --system --no-cache \
    numpy \
    pandas \
    matplotlib \
    seaborn \
    plotly \
    scipy \
    statsmodels \
    sympy

# Phase 4b: Jupyter ecosystem
RUN uv pip install --system --no-cache \
    jupyterlab \
    jupyter \
    notebook \
    ipywidgets \
    voila \
    jupyterlab-git \
    jupyterlab-lsp \
    jupyter-ai

# Phase 4c: Machine learning core (conditional installation)
RUN if [ "$INSTALL_ML_FRAMEWORKS" = "true" ]; then \
    uv pip install --system --no-cache \
        scikit-learn \
        xgboost \
        lightgbm \
        catboost \
        optuna \
        hyperopt; \
    fi

# Phase 4d: Deep learning frameworks (CPU versions, conditional)
RUN if [ "$INSTALL_ML_FRAMEWORKS" = "true" ]; then \
    uv pip install --system --no-cache \
        tensorflow-cpu \
        torch \
        torchvision \
        torchaudio \
        keras \
        --index-url https://download.pytorch.org/whl/cpu; \
    fi

# Phase 4e: Transformers and NLP (conditional)
RUN if [ "$INSTALL_ML_FRAMEWORKS" = "true" ]; then \
    uv pip install --system --no-cache \
        transformers \
        accelerate \
        datasets \
        tokenizers \
        huggingface-hub \
        spacy \
        nltk \
        gensim \
        textblob; \
    fi

# Phase 4f: Computer vision (conditional)
RUN if [ "$INSTALL_ML_FRAMEWORKS" = "true" ]; then \
    uv pip install --system --no-cache \
        opencv-python \
        Pillow \
        scikit-image \
        albumentations \
        imgaug; \
    fi

# Phase 4g: Big data and performance
RUN python3.12 -m pip install \
    dask[complete] \
    polars \
    pyarrow \
    h5py \
    zarr \
    numba \
    cython

# Phase 4h: Web development frameworks
RUN python3.12 -m pip install \
    fastapi \
    uvicorn \
    gunicorn \
    django \
    djangorestframework \
    flask \
    flask-restful \
    flask-sqlalchemy \
    streamlit \
    dash \
    gradio

# Phase 4i: Database and ORM
RUN python3.12 -m pip install \
    sqlalchemy \
    alembic \
    psycopg2-binary \
    pymongo \
    redis \
    clickhouse-driver

# Phase 4j: API and HTTP tools
RUN python3.12 -m pip install \
    httpx \
    requests \
    aiohttp \
    pydantic \
    marshmallow \
    celery \
    dramatiq

# Phase 4k: Development and testing tools
RUN uv pip install --system --no-cache \
    black \
    isort \
    ruff \
    flake8 \
    pylint \
    mypy \
    bandit \
    safety \
    pre-commit \
    pytest \
    pytest-cov \
    pytest-xdist \
    pytest-mock \
    tox \
    nox \
    hypothesis \
    factory-boy \
    python-lsp-server

# Phase 4l: Debugging and profiling
RUN python3.12 -m pip install \
    ipdb \
    pdbpp \
    memory-profiler \
    py-spy \
    line-profiler \
    snakeviz

# Phase 4m: Cloud SDKs and tools (conditional)
RUN if [ "$INSTALL_CLOUD_TOOLS" = "true" ]; then \
    uv pip install --system --no-cache \
        boto3 \
        aws-cdk-lib \
        azure-sdk-for-python \
        google-cloud-storage \
        google-cloud-bigquery; \
    fi

# Phase 4n: Monitoring and logging
RUN python3.12 -m pip install \
    prometheus-client \
    loguru \
    structlog \
    rich \
    opentelemetry-api

# Phase 4o: MLOps and experiment tracking
RUN python3.12 -m pip install \
    wandb \
    mlflow \
    dvc \
    great-expectations

# ========================================
# PHASE 5: EXTERNAL TOOL INSTALLATIONS
# ========================================

# Install starship (modern shell prompt)
RUN curl -fsSL https://starship.rs/install.sh | sh -s -- -y

# Install zoxide (smart cd command)
RUN curl -fsSL https://raw.githubusercontent.com/ajeetdsouza/zoxide/main/install.sh | bash

# Install GitHub CLI
RUN curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg \
    && chmod go+r /usr/share/keyrings/githubcli-archive-keyring.gpg \
    && echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main" | tee /etc/apt/sources.list.d/github-cli.list > /dev/null \
    && apt-get update && apt-get install gh -y \
    && rm -rf /var/lib/apt/lists/*

# Install Helm (conditional)
RUN if [ "$INSTALL_CLOUD_TOOLS" = "true" ]; then \
    curl -fsSL https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash; \
    fi

# Install Terraform (conditional)
RUN if [ "$INSTALL_CLOUD_TOOLS" = "true" ]; then \
    curl -fsSL https://apt.releases.hashicorp.com/gpg | gpg --dearmor | tee /usr/share/keyrings/hashicorp-archive-keyring.gpg \
    && echo "deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main" | tee /etc/apt/sources.list.d/hashicorp.list \
    && apt-get update && apt-get install terraform -y \
    && rm -rf /var/lib/apt/lists/*; \
    fi

# Install AWS CLI (conditional)
RUN if [ "$INSTALL_CLOUD_TOOLS" = "true" ]; then \
    curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip" \
    && unzip awscliv2.zip \
    && ./aws/install \
    && rm -rf aws awscliv2.zip; \
    fi

# Install Azure CLI (conditional)
RUN if [ "$INSTALL_CLOUD_TOOLS" = "true" ]; then \
    curl -sL https://aka.ms/InstallAzureCLIDeb | bash; \
    fi

# Install Google Cloud SDK (conditional)
RUN if [ "$INSTALL_CLOUD_TOOLS" = "true" ]; then \
    echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list \
    && curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key --keyring /usr/share/keyrings/cloud.google.gpg add - \
    && apt-get update && apt-get install google-cloud-cli -y \
    && rm -rf /var/lib/apt/lists/*; \
    fi

# Install security tools (conditional)
RUN if [ "$INSTALL_SECURITY_TOOLS" = "true" ]; then \
    apt-get update && apt-get install -y \
        trivy \
        && rm -rf /var/lib/apt/lists/*; \
    fi

# ========================================
# PHASE 6: USER MANAGEMENT
# ========================================

# Remove container image user and group if they conflict with the host user
RUN if grep -q ":${USER_UID}:" /etc/passwd; then \
      userdel --force -r $(grep ":${USER_UID}:" /etc/passwd | cut -d: -f1); \
    fi && \
    if [ "$DEBUG" = "true" ]; then \
        echo "User with UID ${USER_UID} deleted if it existed."; \
    fi && \
    if grep -q ":${USER_GID}:" /etc/group; then \
      groupdel $(grep ":${USER_GID}:" /etc/group | cut -d: -f1); \
    fi && \
    if [ "$DEBUG" = "true" ]; then \
        echo "Group with GID ${USER_GID} deleted if it existed."; \
    fi

# Create the user and group to match the host user
RUN set -eux && \
    if [ "$DEBUG" = "true" ]; then \
        echo "Creating group if it does not exist..."; \
    fi && \
    if ! getent group "${USER_GID}" >/dev/null; then \
        groupadd --gid "${USER_GID}" "${USERNAME}" || (echo "Error: Failed to create group with GID ${USER_GID}" && exit 1); \
    else \
        if [ "$DEBUG" = "true" ]; then \
            echo "Group with GID ${USER_GID} already exists."; \
        fi; \
    fi && \
    if [ "$DEBUG" = "true" ]; then \
        echo "Creating user if it does not exist..."; \
    fi && \
    if ! id -u "${USERNAME}" >/dev/null 2>&1; then \
        useradd --uid "${USER_UID}" --gid "${USER_GID}" -m -s /bin/zsh "${USERNAME}" || (echo "Error: Failed to create user ${USERNAME} with UID ${USER_UID} and GID ${USER_GID}" && exit 1); \
    else \
        if [ "$DEBUG" = "true" ]; then \
            echo "User ${USERNAME} already exists."; \
        fi; \
    fi && \
    if [ "$DEBUG" = "true" ]; then \
        echo "Adding user to important groups..."; \
    fi && \
    usermod -aG sudo,docker,www-data "${USERNAME}" && \
    SUDO_FILE="/etc/sudoers.d/${USERNAME}" && \
    SUDO_LINE="${USERNAME} ALL=(ALL) NOPASSWD:ALL" && \
    touch "${SUDO_FILE}" && \
    grep -qF -- "${SUDO_LINE}" "${SUDO_FILE}" || echo "${SUDO_LINE}" >> "${SUDO_FILE}" && \
    chmod 0440 "${SUDO_FILE}" && \
    if [ "$DEBUG" = "true" ]; then \
        echo "Verifying user creation..."; \
    fi && \
    getent passwd "${USERNAME}" || (echo "Error: User ${USERNAME} was not created!" && exit 1)

# Switch to the created user for user-specific configurations
USER ${USERNAME}

# Set up user home directory paths
ENV HOME=/home/${USERNAME}
ENV USER=${USERNAME}
WORKDIR ${HOME}

# ========================================
# PHASE 7: USER-SPECIFIC CONFIGURATIONS
# ========================================

# Install Oh My Zsh
RUN sh -c "$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)" "" --unattended

# Install Oh My Zsh plugins
RUN git clone https://github.com/zsh-users/zsh-autosuggestions ${HOME}/.oh-my-zsh/custom/plugins/zsh-autosuggestions && \
    git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${HOME}/.oh-my-zsh/custom/plugins/zsh-syntax-highlighting

# Configure .zshrc with Python-specific settings
RUN echo 'export PATH="/home/'${USERNAME}'/.local/bin:$PATH"' >> ${HOME}/.zshrc && \
    echo 'export PATH="/home/'${USERNAME}'/.poetry/bin:$PATH"' >> ${HOME}/.zshrc && \
    echo 'export PATH="/home/'${USERNAME}'/.pyenv/bin:$PATH"' >> ${HOME}/.zshrc && \
    echo 'eval "$(pyenv init -)"' >> ${HOME}/.zshrc && \
    echo 'eval "$(pyenv virtualenv-init -)"' >> ${HOME}/.zshrc && \
    echo 'eval "$(starship init zsh)"' >> ${HOME}/.zshrc && \
    echo 'eval "$(zoxide init zsh)"' >> ${HOME}/.zshrc && \
    sed -i 's/plugins=(git)/plugins=(git python pip poetry django docker docker-compose kubectl helm aws azure gcloud zsh-autosuggestions zsh-syntax-highlighting)/g' ${HOME}/.zshrc

# Add Python-specific aliases
RUN cat >> ${HOME}/.zshrc << 'EOF'

# Python-specific aliases
alias py='python3'
alias py3='python3'
alias python='python3'
alias pip='python3 -m pip'
alias pip3='python3 -m pip'
alias jupyter='jupyter lab'
alias lab='jupyter lab'
alias notebook='jupyter notebook'
alias nb='jupyter notebook'

# Package management
alias poetry-install='poetry install'
alias pi='poetry install'
alias poetry-add='poetry add'
alias pa='poetry add'
alias poetry-shell='poetry shell'
alias ps='poetry shell'

# Code quality
alias black-check='black --check .'
alias bc='black --check .'
alias isort-check='isort --check .'
alias ic='isort --check .'
alias mypy-check='mypy .'
alias mc='mypy .'
alias flake8-check='flake8 .'
alias fc='flake8 .'
alias test='pytest'
alias t='pytest'
alias coverage='pytest --cov'
alias cov='pytest --cov'

# Modern CLI alternatives
alias ll='ls -la'
alias la='ls -la'
alias ls='ls'
alias cat='batcat'
alias find='fd'
alias grep='rg'

# Docker & Kubernetes  
alias d='docker'
alias dc='docker-compose'
alias dps='docker ps'
alias di='docker images'
alias dex='docker exec -it'
alias k='kubectl'
alias kgp='kubectl get pods'
alias kgs='kubectl get services'
alias kgd='kubectl get deployments'

# Git aliases
alias gs='git status'
alias ga='git add'
alias gc='git commit'
alias gp='git push'
alias gl='git pull'
alias gco='git checkout'
alias gb='git branch'
alias gd='git diff'
alias glog='git log --oneline --graph --decorate'

EOF

# Create common Python project structure
RUN mkdir -p ${HOME}/workspace/{notebooks,src,data,models,tests,docs,scripts,docker,kubernetes,terraform,requirements}

# Create a sample requirements.txt structure
RUN mkdir -p ${HOME}/workspace/requirements && \
    echo "# Main dependencies" > ${HOME}/workspace/requirements/requirements.txt && \
    echo "# Development dependencies" > ${HOME}/workspace/requirements/dev-requirements.txt && \
    echo "# Testing dependencies" > ${HOME}/workspace/requirements/test-requirements.txt

# Create sample configuration files
RUN echo "[tool.poetry]" > ${HOME}/workspace/pyproject.toml && \
    echo 'name = "python-project"' >> ${HOME}/workspace/pyproject.toml && \
    echo 'version = "0.1.0"' >> ${HOME}/workspace/pyproject.toml && \
    echo 'description = ""' >> ${HOME}/workspace/pyproject.toml && \
    echo 'authors = ["Your Name <you@example.com>"]' >> ${HOME}/workspace/pyproject.toml && \
    echo "" >> ${HOME}/workspace/pyproject.toml && \
    echo "[tool.poetry.dependencies]" >> ${HOME}/workspace/pyproject.toml && \
    echo 'python = "^3.12"' >> ${HOME}/workspace/pyproject.toml

# Create ruff configuration
RUN echo "[tool.ruff]" > ${HOME}/workspace/.ruff.toml && \
    echo 'target-version = "py312"' >> ${HOME}/workspace/.ruff.toml && \
    echo 'line-length = 88' >> ${HOME}/workspace/.ruff.toml && \
    echo 'select = ["E", "W", "F", "I", "N", "B", "C4", "UP", "ANN", "S", "T20", "RET", "SIM", "ARG", "ERA", "RUF"]' >> ${HOME}/workspace/.ruff.toml

# Set Python version as default
RUN echo 'export PYTHON_VERSION='${PYTHON_VERSION} >> ${HOME}/.zshrc

# Set working directory
WORKDIR /workspace

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD python${PYTHON_VERSION} --version || exit 1

# Final message
RUN echo "🐍 Python DevBench Monster setup complete! 🚀"